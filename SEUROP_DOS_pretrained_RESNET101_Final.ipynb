{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa527c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful libraries\n",
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7331dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 2022\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a62a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL='RESNET101'\n",
    "TYPE = 'SEUROP'\n",
    "N_Fold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f61715",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASE_MODEL == 'MobileNet':\n",
    "    from keras.applications.mobilenet_v2 import MobileNetV2 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'DenseNet121':\n",
    "    from keras.applications.densenet import DenseNet121 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'VGG16':\n",
    "    from keras.applications.vgg16 import VGG16 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'RESNET50':\n",
    "    from keras.applications.resnet import ResNet50 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'RESNET50V2':\n",
    "    from keras.applications.resnet_v2 import ResNet50V2 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'RESNET101':\n",
    "    from keras.applications.resnet import ResNet101 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'RESNET101V2':\n",
    "    from keras.applications.resnet_v2 import ResNet101V2 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3) \n",
    "elif BASE_MODEL == 'RESNET152':\n",
    "    from keras.applications.resnet import ResNet152 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'InceptionV3':\n",
    "    from keras.applications.inception_v3 import InceptionV3 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (299, 299, 3)\n",
    "elif BASE_MODEL == 'Xception':\n",
    "    from keras.applications.xception import Xception as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (299,299,3)\n",
    "elif BASE_MODEL == 'DenseNet169': \n",
    "    from keras.applications.densenet import DenseNet169 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'DenseNet121':\n",
    "    from keras.applications.densenet import DenseNet121 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL == 'VGG19':\n",
    "    from keras.applications.vgg19 import VGG19 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3)\n",
    "elif BASE_MODEL =='EfficientNetB0':\n",
    "    from keras.applications.efficientnet import EfficientNetB0 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (224,224,3) \n",
    "elif BASE_MODEL == 'EfficientNetB1':\n",
    "    from keras.applications.efficientnet import EfficientNetB1 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (240,240,3) \n",
    "elif BASE_MODEL == 'EfficientNetB2':\n",
    "    from keras.applications.efficientnet import EfficientNetB2 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (260,260,3) \n",
    "elif BASE_MODEL == 'EfficientNetB3':\n",
    "    from keras.applications.efficientnet import EfficientNetB3 as BModel, preprocess_input, decode_predictions\n",
    "    IMG_SIZE = (300,300,3)\n",
    "else:\n",
    "    raise ValueError('Unknown model: {}'.format(BASE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17225dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the images\n",
    "def read_data(img_number_init, img_number_fin):\n",
    "    # access to folder who contain the image of DOS\n",
    "    path = 'DOS\\\\imagesCropees\\\\'\n",
    "    # full path : 'C:\\Users\\Admin\\Documents\\projet_carcasses_Travail_brouillon\\DOS\\imagesCropees\\' 'image' '2' '.jpg'\n",
    "    img = path + 'image'+str(img_number_init)+'.jpg'\n",
    "    img = image.load_img(img, target_size=IMG_SIZE)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    for i in range(img_number_init+1,img_number_fin+1):\n",
    "        img = path+'image'+str(i)+'.jpg'\n",
    "        img = image.load_img(img, target_size=IMG_SIZE)\n",
    "        xx = image.img_to_array(img)\n",
    "        xx = np.expand_dims(xx, axis=0)\n",
    "        x = np.vstack([x, xx])\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e8f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "img_removed = [23, 43, 113, 153, 170, 187, 222, 230, 289, 316, 350, 395, 429, 483, 518, 541, 556, 566, 577, 652]\n",
    "# NB : we need to remove the date cause \"misunderstand\" for the training procedures.\n",
    "# Read data\n",
    "nbr = len(img_removed)\n",
    "\n",
    "X = read_data(3, img_removed[0]-1)\n",
    "\n",
    "for i in range(nbr-1):\n",
    "    X = np.vstack([X, read_data(img_removed[i]+1, img_removed[i+1]-1)])\n",
    "\n",
    "df = pd.read_excel ('classification.xlsx', engine='openpyxl')\n",
    "# transform categorical to numeric\n",
    "df['Conf'].replace(['U','R','O','P'],[0, 1, 2, 3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a4c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = df['Conf']\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "y = y_all[1:img_removed[0]-1]\n",
    "\n",
    "for i in range(nbr-1):\n",
    "    y = np.hstack([y, y_all[img_removed[i]:img_removed[i+1]-1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05985570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation of data in train-validation-test with rate of 60%-20%-20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = preprocess_input(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c211c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    # load the convolutional base model and set layers as not trainable\n",
    "    base_model = BModel(include_top=False, input_shape=IMG_SIZE)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # add new classifier layers\n",
    "    x = layers.Flatten()(base_model.layers[-1].output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(256, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.Dropout(0.55)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.Dropout(0.55)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    output = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "    # define new model, compile and fit\n",
    "    model = tensorflow.keras.Model(inputs=base_model.inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a7ef74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 11s 707ms/step - loss: 1.8539 - accuracy: 0.2887 - val_loss: 15.9213 - val_accuracy: 0.3452\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.34524, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnngo1\\Anaconda3\\envs\\GPU-2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "6/6 [==============================] - 1s 240ms/step - loss: 1.4592 - accuracy: 0.3601 - val_loss: 6.6201 - val_accuracy: 0.3690\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.34524 to 0.36905, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 1s 241ms/step - loss: 1.2884 - accuracy: 0.4613 - val_loss: 4.0574 - val_accuracy: 0.4167\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.36905 to 0.41667, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 1s 244ms/step - loss: 1.0523 - accuracy: 0.5357 - val_loss: 3.0153 - val_accuracy: 0.4226\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.41667 to 0.42262, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 1s 240ms/step - loss: 1.0114 - accuracy: 0.6131 - val_loss: 2.2078 - val_accuracy: 0.4702\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.42262 to 0.47024, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 1s 242ms/step - loss: 0.8815 - accuracy: 0.6726 - val_loss: 1.8137 - val_accuracy: 0.5179\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.47024 to 0.51786, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 1s 242ms/step - loss: 0.8159 - accuracy: 0.6756 - val_loss: 1.6430 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.51786 to 0.54167, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 1s 242ms/step - loss: 0.8427 - accuracy: 0.6756 - val_loss: 1.5243 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.54167 to 0.57143, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 1s 244ms/step - loss: 0.6850 - accuracy: 0.7351 - val_loss: 1.4150 - val_accuracy: 0.5893\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.57143 to 0.58929, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 1s 244ms/step - loss: 0.6067 - accuracy: 0.7887 - val_loss: 1.3460 - val_accuracy: 0.6012\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.58929 to 0.60119, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 1s 244ms/step - loss: 0.5633 - accuracy: 0.7917 - val_loss: 1.3027 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.60119 to 0.61905, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 1s 244ms/step - loss: 0.4619 - accuracy: 0.8393 - val_loss: 1.2343 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.61905\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 1s 244ms/step - loss: 0.4322 - accuracy: 0.8661 - val_loss: 1.1985 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.61905 to 0.62500, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 1s 245ms/step - loss: 0.4546 - accuracy: 0.8452 - val_loss: 1.1931 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.62500\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 1s 243ms/step - loss: 0.3455 - accuracy: 0.8899 - val_loss: 1.1825 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.62500\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 1s 245ms/step - loss: 0.2923 - accuracy: 0.9345 - val_loss: 1.1656 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.62500\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 1s 247ms/step - loss: 0.2754 - accuracy: 0.9494 - val_loss: 1.1736 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.62500\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.2921 - accuracy: 0.9226 - val_loss: 1.1660 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.62500 to 0.64881, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.2202 - accuracy: 0.9286 - val_loss: 1.1540 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64881\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.2184 - accuracy: 0.9345 - val_loss: 1.1318 - val_accuracy: 0.6369\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64881\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.2092 - accuracy: 0.9524 - val_loss: 1.1117 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64881\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.1847 - accuracy: 0.9494 - val_loss: 1.1187 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.64881 to 0.65476, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.1799 - accuracy: 0.9554 - val_loss: 1.1370 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.65476\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 1s 245ms/step - loss: 0.1818 - accuracy: 0.9554 - val_loss: 1.1223 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.65476\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 1s 244ms/step - loss: 0.1939 - accuracy: 0.9405 - val_loss: 1.1228 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.65476 to 0.66667, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 1s 247ms/step - loss: 0.1582 - accuracy: 0.9702 - val_loss: 1.1286 - val_accuracy: 0.6310\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66667\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.1333 - accuracy: 0.9673 - val_loss: 1.1188 - val_accuracy: 0.6369\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66667\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.1571 - accuracy: 0.9613 - val_loss: 1.1108 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66667\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.1222 - accuracy: 0.9702 - val_loss: 1.1096 - val_accuracy: 0.6369\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66667\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.1201 - accuracy: 0.9792 - val_loss: 1.0960 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66667\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.1714 - accuracy: 0.9464 - val_loss: 1.0805 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66667\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.1054 - accuracy: 0.9792 - val_loss: 1.0713 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.66667\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.1289 - accuracy: 0.9702 - val_loss: 1.0661 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66667\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 1s 247ms/step - loss: 0.1221 - accuracy: 0.9732 - val_loss: 1.0804 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.66667 to 0.67857, saving model to RESNET101\\622SEUROPRESNET1011.hdf5\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 1s 247ms/step - loss: 0.1206 - accuracy: 0.9702 - val_loss: 1.1039 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67857\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 1s 248ms/step - loss: 0.1019 - accuracy: 0.9732 - val_loss: 1.1161 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67857\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.0955 - accuracy: 0.9732 - val_loss: 1.1198 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67857\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 1s 247ms/step - loss: 0.0720 - accuracy: 0.9911 - val_loss: 1.1093 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67857\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.1090 - accuracy: 0.9583 - val_loss: 1.1131 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.67857\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 1s 248ms/step - loss: 0.0753 - accuracy: 0.9851 - val_loss: 1.1314 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67857\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.0748 - accuracy: 0.9762 - val_loss: 1.1424 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67857\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.0623 - accuracy: 0.9940 - val_loss: 1.1504 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.67857\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.0632 - accuracy: 0.9911 - val_loss: 1.1629 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67857\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0741 - accuracy: 0.9851 - val_loss: 1.1933 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67857\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.0903 - accuracy: 0.9762 - val_loss: 1.1679 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.67857\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.1237 - accuracy: 0.9524 - val_loss: 1.1505 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.67857\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.0744 - accuracy: 0.9821 - val_loss: 1.1701 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.67857\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0780 - accuracy: 0.9821 - val_loss: 1.2032 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.67857\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.0643 - accuracy: 0.9851 - val_loss: 1.1827 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.67857\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0522 - accuracy: 0.9851 - val_loss: 1.1679 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.67857\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.1092 - accuracy: 0.9613 - val_loss: 1.1635 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.67857\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0872 - accuracy: 0.9762 - val_loss: 1.1772 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.67857\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.0631 - accuracy: 0.9792 - val_loss: 1.1705 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.67857\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0495 - accuracy: 0.9940 - val_loss: 1.1570 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.67857\n",
      "*************************\n",
      "Training next model\n",
      "*************************\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 8s 478ms/step - loss: 1.8903 - accuracy: 0.3065 - val_loss: 5.1976 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54167, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 1.4913 - accuracy: 0.4196 - val_loss: 2.9447 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.54167\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 1.3323 - accuracy: 0.4851 - val_loss: 2.1829 - val_accuracy: 0.5536\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.54167 to 0.55357, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 1.1227 - accuracy: 0.5506 - val_loss: 1.8976 - val_accuracy: 0.5536\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.55357\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 1.0166 - accuracy: 0.5952 - val_loss: 1.6278 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.55357 to 0.58333, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.9058 - accuracy: 0.6548 - val_loss: 1.4193 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.58333\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.8223 - accuracy: 0.6935 - val_loss: 1.2987 - val_accuracy: 0.5893\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.58333 to 0.58929, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.7250 - accuracy: 0.7321 - val_loss: 1.2205 - val_accuracy: 0.5774\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.58929\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 1s 248ms/step - loss: 0.6812 - accuracy: 0.7530 - val_loss: 1.1636 - val_accuracy: 0.5774\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.58929\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.5423 - accuracy: 0.8274 - val_loss: 1.1248 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.58929 to 0.61905, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.5459 - accuracy: 0.7946 - val_loss: 1.1169 - val_accuracy: 0.6369\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.61905 to 0.63690, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.4691 - accuracy: 0.8393 - val_loss: 1.0977 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.63690 to 0.64881, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 1s 248ms/step - loss: 0.3951 - accuracy: 0.8393 - val_loss: 1.0680 - val_accuracy: 0.6369\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64881\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.3777 - accuracy: 0.8780 - val_loss: 1.0122 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.64881 to 0.66667, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.3052 - accuracy: 0.9137 - val_loss: 0.9858 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66667\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.3681 - accuracy: 0.9196 - val_loss: 0.9916 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66667\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.2797 - accuracy: 0.9315 - val_loss: 1.0015 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66667\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.2525 - accuracy: 0.9464 - val_loss: 0.9944 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66667\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.2477 - accuracy: 0.9226 - val_loss: 0.9863 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66667\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.2416 - accuracy: 0.9256 - val_loss: 0.9718 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66667\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.2501 - accuracy: 0.9286 - val_loss: 0.9571 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66667\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1728 - accuracy: 0.9762 - val_loss: 0.9598 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66667\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1902 - accuracy: 0.9554 - val_loss: 0.9490 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66667\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 252ms/step - loss: 0.1886 - accuracy: 0.9435 - val_loss: 0.9481 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66667\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.1307 - accuracy: 0.9702 - val_loss: 0.9409 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66667\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.1483 - accuracy: 0.9702 - val_loss: 0.9354 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66667\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.1476 - accuracy: 0.9524 - val_loss: 0.9347 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66667\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1256 - accuracy: 0.9613 - val_loss: 0.9283 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66667\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1197 - accuracy: 0.9702 - val_loss: 0.9220 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66667\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.1209 - accuracy: 0.9702 - val_loss: 0.9135 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66667\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1023 - accuracy: 0.9851 - val_loss: 0.9159 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.66667 to 0.67262, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.1228 - accuracy: 0.9643 - val_loss: 0.8999 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.67262 to 0.67857, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0835 - accuracy: 0.9762 - val_loss: 0.8843 - val_accuracy: 0.6845\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.67857 to 0.68452, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1093 - accuracy: 0.9702 - val_loss: 0.8721 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.68452 to 0.69048, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0781 - accuracy: 0.9881 - val_loss: 0.8646 - val_accuracy: 0.7024\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.69048 to 0.70238, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0944 - accuracy: 0.9792 - val_loss: 0.8640 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.70238 to 0.71429, saving model to RESNET101\\622SEUROPRESNET1012.hdf5\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.0735 - accuracy: 0.9821 - val_loss: 0.8678 - val_accuracy: 0.7083\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.71429\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1040 - accuracy: 0.9821 - val_loss: 0.8640 - val_accuracy: 0.7024\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.71429\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.0851 - accuracy: 0.9762 - val_loss: 0.8643 - val_accuracy: 0.6964\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.71429\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0726 - accuracy: 0.9881 - val_loss: 0.8636 - val_accuracy: 0.6964\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.71429\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 1s 255ms/step - loss: 0.0593 - accuracy: 0.9940 - val_loss: 0.8616 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.71429\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0831 - accuracy: 0.9762 - val_loss: 0.8627 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.71429\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0626 - accuracy: 0.9940 - val_loss: 0.8598 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.71429\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0738 - accuracy: 0.9792 - val_loss: 0.8596 - val_accuracy: 0.6964\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.71429\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0558 - accuracy: 0.9911 - val_loss: 0.8591 - val_accuracy: 0.7024\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.71429\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0539 - accuracy: 0.9911 - val_loss: 0.8681 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.71429\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.0510 - accuracy: 0.9940 - val_loss: 0.8880 - val_accuracy: 0.6964\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.71429\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0472 - accuracy: 0.9911 - val_loss: 0.8971 - val_accuracy: 0.6964\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.71429\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0406 - accuracy: 0.9970 - val_loss: 0.9033 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.71429\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0394 - accuracy: 0.9970 - val_loss: 0.9104 - val_accuracy: 0.6964\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.71429\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0718 - accuracy: 0.9792 - val_loss: 0.9038 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.71429\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0565 - accuracy: 0.9881 - val_loss: 0.8993 - val_accuracy: 0.6845\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.71429\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0453 - accuracy: 0.9940 - val_loss: 0.9049 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.71429\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0382 - accuracy: 0.9970 - val_loss: 0.9124 - val_accuracy: 0.6964\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.71429\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0378 - accuracy: 0.9940 - val_loss: 0.9198 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.71429\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0441 - accuracy: 0.9911 - val_loss: 0.9265 - val_accuracy: 0.6845\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.71429\n",
      "*************************\n",
      "Training next model\n",
      "*************************\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 8s 594ms/step - loss: 1.8846 - accuracy: 0.2946 - val_loss: 10.6943 - val_accuracy: 0.3869\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38690, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 1.4113 - accuracy: 0.4077 - val_loss: 4.9269 - val_accuracy: 0.4345\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.38690 to 0.43452, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 1.2654 - accuracy: 0.4792 - val_loss: 3.3254 - val_accuracy: 0.4583\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.43452 to 0.45833, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 1.1775 - accuracy: 0.5089 - val_loss: 2.8489 - val_accuracy: 0.4643\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.45833 to 0.46429, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 1.0631 - accuracy: 0.5893 - val_loss: 2.3188 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.46429 to 0.50000, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 250ms/step - loss: 1.0628 - accuracy: 0.6071 - val_loss: 1.9815 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.50000 to 0.52381, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.7950 - accuracy: 0.6994 - val_loss: 1.7675 - val_accuracy: 0.5595\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.52381 to 0.55952, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.7371 - accuracy: 0.6994 - val_loss: 1.6591 - val_accuracy: 0.5476\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.55952\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.6567 - accuracy: 0.7589 - val_loss: 1.5843 - val_accuracy: 0.5476\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.55952\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.5842 - accuracy: 0.8244 - val_loss: 1.4648 - val_accuracy: 0.5893\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.55952 to 0.58929, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.4951 - accuracy: 0.8065 - val_loss: 1.4005 - val_accuracy: 0.5893\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.58929\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.4228 - accuracy: 0.8750 - val_loss: 1.3965 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.58929\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.4097 - accuracy: 0.8750 - val_loss: 1.3943 - val_accuracy: 0.6012\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.58929 to 0.60119, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.4023 - accuracy: 0.9018 - val_loss: 1.3780 - val_accuracy: 0.6012\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.60119\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.3508 - accuracy: 0.9048 - val_loss: 1.3320 - val_accuracy: 0.5893\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.60119\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.3132 - accuracy: 0.8988 - val_loss: 1.3164 - val_accuracy: 0.5893\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.60119\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.2947 - accuracy: 0.9137 - val_loss: 1.2945 - val_accuracy: 0.5774\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.60119\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.2492 - accuracy: 0.9375 - val_loss: 1.2839 - val_accuracy: 0.5893\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.60119\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.2782 - accuracy: 0.9107 - val_loss: 1.2478 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.60119 to 0.60714, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.2255 - accuracy: 0.9435 - val_loss: 1.1797 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.60714 to 0.62500, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.2324 - accuracy: 0.9315 - val_loss: 1.1420 - val_accuracy: 0.5893\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.62500\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.1698 - accuracy: 0.9702 - val_loss: 1.1222 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.62500\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.1938 - accuracy: 0.9375 - val_loss: 1.1140 - val_accuracy: 0.5952\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.62500\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1809 - accuracy: 0.9554 - val_loss: 1.1267 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.62500\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1588 - accuracy: 0.9673 - val_loss: 1.1391 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.62500\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.1639 - accuracy: 0.9554 - val_loss: 1.1693 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.62500\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.1378 - accuracy: 0.9673 - val_loss: 1.2051 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.62500\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.1089 - accuracy: 0.9821 - val_loss: 1.2226 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.62500\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1514 - accuracy: 0.9554 - val_loss: 1.2352 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.62500\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1152 - accuracy: 0.9702 - val_loss: 1.2265 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.62500\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.1378 - accuracy: 0.9613 - val_loss: 1.2033 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.62500\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.1242 - accuracy: 0.9613 - val_loss: 1.1639 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.62500 to 0.64286, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0979 - accuracy: 0.9762 - val_loss: 1.1621 - val_accuracy: 0.6310\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.64286\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.0969 - accuracy: 0.9851 - val_loss: 1.1656 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64286\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.1326 - accuracy: 0.9643 - val_loss: 1.1814 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.64286\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 1s 256ms/step - loss: 0.1166 - accuracy: 0.9762 - val_loss: 1.2025 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.64286\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 1s 256ms/step - loss: 0.1033 - accuracy: 0.9732 - val_loss: 1.2309 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.64286\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 1s 257ms/step - loss: 0.0935 - accuracy: 0.9762 - val_loss: 1.2949 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.64286\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 1s 255ms/step - loss: 0.0956 - accuracy: 0.9792 - val_loss: 1.3741 - val_accuracy: 0.5476\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.64286\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.0742 - accuracy: 0.9821 - val_loss: 1.4283 - val_accuracy: 0.5357\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.64286\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 1s 262ms/step - loss: 0.0882 - accuracy: 0.9851 - val_loss: 1.3855 - val_accuracy: 0.5298\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.64286\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 1s 257ms/step - loss: 0.0805 - accuracy: 0.9792 - val_loss: 1.3284 - val_accuracy: 0.5536\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.64286\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 2s 264ms/step - loss: 0.0849 - accuracy: 0.9762 - val_loss: 1.2807 - val_accuracy: 0.5952\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.64286\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 1s 262ms/step - loss: 0.0697 - accuracy: 0.9821 - val_loss: 1.2496 - val_accuracy: 0.6012\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.64286\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 1s 261ms/step - loss: 0.0728 - accuracy: 0.9792 - val_loss: 1.2402 - val_accuracy: 0.6310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.64286\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.0793 - accuracy: 0.9851 - val_loss: 1.2209 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.64286 to 0.64881, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.0680 - accuracy: 0.9881 - val_loss: 1.2164 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.64881 to 0.65476, saving model to RESNET101\\622SEUROPRESNET1013.hdf5\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 1s 259ms/step - loss: 0.0667 - accuracy: 0.9851 - val_loss: 1.2436 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.65476\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 1s 256ms/step - loss: 0.0644 - accuracy: 0.9911 - val_loss: 1.3322 - val_accuracy: 0.5774\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.65476\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 2s 266ms/step - loss: 0.0487 - accuracy: 0.9911 - val_loss: 1.3792 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.65476\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 1s 264ms/step - loss: 0.0705 - accuracy: 0.9821 - val_loss: 1.3473 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.65476\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.0587 - accuracy: 0.9851 - val_loss: 1.3035 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.65476\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 1s 263ms/step - loss: 0.0580 - accuracy: 0.9851 - val_loss: 1.2614 - val_accuracy: 0.6310\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.65476\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 1s 259ms/step - loss: 0.0876 - accuracy: 0.9732 - val_loss: 1.2507 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.65476\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 1s 256ms/step - loss: 0.0507 - accuracy: 0.9881 - val_loss: 1.2467 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.65476\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0472 - accuracy: 0.9911 - val_loss: 1.2450 - val_accuracy: 0.6012\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.65476\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0591 - accuracy: 0.9851 - val_loss: 1.2560 - val_accuracy: 0.6012\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.65476\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.0594 - accuracy: 0.9851 - val_loss: 1.2550 - val_accuracy: 0.6310\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.65476\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.0374 - accuracy: 0.9970 - val_loss: 1.2601 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.65476\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0477 - accuracy: 0.9911 - val_loss: 1.2765 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.65476\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0431 - accuracy: 0.9940 - val_loss: 1.3100 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.65476\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 1s 255ms/step - loss: 0.0502 - accuracy: 0.9851 - val_loss: 1.3389 - val_accuracy: 0.6310\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.65476\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 1s 256ms/step - loss: 0.0304 - accuracy: 0.9970 - val_loss: 1.3657 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.65476\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0518 - accuracy: 0.9911 - val_loss: 1.3720 - val_accuracy: 0.6310\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.65476\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.0374 - accuracy: 0.9940 - val_loss: 1.3811 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.65476\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.3733 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.65476\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.0542 - accuracy: 0.9881 - val_loss: 1.3750 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.65476\n",
      "*************************\n",
      "Training next model\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "# store the trained models in a list\n",
    "list_of_models = []\n",
    "list_of_histories = []\n",
    "count = 0\n",
    "\n",
    "# we use k-Fold (i.e. we will build k models)\n",
    "kfold = StratifiedKFold(n_splits=N_Fold, shuffle=True, random_state=2)\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train,y_train): \n",
    "    count = count + 1\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor = \"val_accuracy\",patience = 20),\n",
    "        ModelCheckpoint(\n",
    "        filepath = BASE_MODEL+'\\\\622'+TYPE+BASE_MODEL+str(count)+'.hdf5',\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1)\n",
    "    ]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # building the models\n",
    "    history=model.fit(X_train[train_index],y_train[train_index],epochs=100, batch_size = 64,\n",
    "                   callbacks=callbacks,\n",
    "                   validation_data = (X_train[val_index],y_train[val_index]))\n",
    "    list_of_models.append(model)\n",
    "    list_of_histories.append(history)\n",
    "    print('*************************')\n",
    "    print('Training next model')\n",
    "    print('*************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21cec0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying curves of loss and accuracy during training\n",
    "liste_precisions =[]\n",
    "\n",
    "for i in range(N_Fold):\n",
    "    acc = list_of_histories[i].history[\"accuracy\"]\n",
    "    val_acc = list_of_histories[i].history[\"val_accuracy\"]\n",
    "    loss = list_of_histories[i].history[\"loss\"]\n",
    "    val_loss = list_of_histories[i].history[\"val_loss\"]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    fig= plt.figure()\n",
    "    plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cef0e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "all_model=[]\n",
    "\n",
    "for i in range(N_Fold):\n",
    "    all_model.append(load_model(BASE_MODEL+'\\\\622'+TYPE+BASE_MODEL+str(i+1)+'.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c093178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7936507936507936\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "\n",
    "    model_predict_moyenne = all_model[0].predict(X_test)\n",
    "\n",
    "    for i in range(1,N_Fold):\n",
    "        model_predict_moyenne = model_predict_moyenne + all_model[i].predict(X_test)\n",
    "\n",
    "    model_predict_moyenne = model_predict_moyenne/N_Fold\n",
    "\n",
    "    # Calcul précision de méthode k_fold\n",
    "    print(np.mean(np.argmax(model_predict_moyenne, axis = 1)==y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6588206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 14, 14, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 14, 14, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 14, 14, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 14, 14, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 14, 14, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 14, 14, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 14, 14, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 14, 14, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 14, 14, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 14, 14, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 14, 14, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 14, 14, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 14, 14, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 14, 14, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 14, 14, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 14, 14, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 14, 14, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 14, 14, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 14, 14, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 14, 14, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 14, 14, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 14, 14, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 14, 14, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 14, 14, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 14, 14, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 14, 14, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 14, 14, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 14, 14, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 14, 14, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 14, 14, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 14, 14, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 14, 14, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 14, 14, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 14, 14, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 14, 14, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 14, 14, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 14, 14, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100352)       401408      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          25690368    batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            516         batch_normalization_8[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 68,784,900\n",
      "Trainable params: 25,925,252\n",
      "Non-trainable params: 42,859,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3db7d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
