{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa527c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful libraries\n",
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dba56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a couple of vector with their size.\n",
    "IMG_SIZE = (720,240)\n",
    "# NB1: In tensorflow and keras IMG_SIZE = (Height,width).\n",
    "# NB2: Each image of dataset \"DOS\" has a size (240x270) pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d5cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 2022\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14de544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL='RESNET101V2'\n",
    "N_Fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f2040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet_v2 import ResNet101V2 as BModel, preprocess_input, decode_predictions\n",
    "IMG_SIZE = (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17225dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the images\n",
    "def read_data1(img_number_init, img_number_fin):\n",
    "    path = 'DOS\\\\imagesCropees\\\\'\n",
    "    img = path + 'image'+str(img_number_init)+'.jpg'\n",
    "    img = image.load_img(img, target_size=IMG_SIZE[0:2])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    for i in range(img_number_init+1,img_number_fin+1):\n",
    "        img = path+'image'+str(i)+'.jpg'\n",
    "        img = image.load_img(img, target_size=IMG_SIZE[0:2])\n",
    "        xx = image.img_to_array(img)\n",
    "        xx = np.expand_dims(xx, axis=0)\n",
    "        x = np.vstack([x, xx])\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3816740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data2(img_number_init, img_number_fin):\n",
    "    path = 'FLANC\\\\imagesCropees\\\\'\n",
    "    img = path + 'image'+str(img_number_init)+'.jpg'\n",
    "    img = image.load_img(img, target_size=IMG_SIZE[0:2])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    for i in range(img_number_init+1,img_number_fin+1):\n",
    "        img = path+'image'+str(i)+'.jpg'\n",
    "        img = image.load_img(img, target_size=IMG_SIZE[0:2])\n",
    "        xx = image.img_to_array(img)\n",
    "        xx = np.expand_dims(xx, axis=0)\n",
    "        x = np.vstack([x, xx])\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e8f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "img_removed = [23, 43, 113, 153, 170, 187, 222, 230, 289, 316, 350, 395, 429, 483, 518, 541, 556, 566, 577, 652]\n",
    "# NB : we need to remove the date cause \"misunderstand\" for the training procedures.\n",
    "# Read data\n",
    "nbr = len(img_removed)\n",
    "\n",
    "X1 = read_data1(3, img_removed[0]-1)\n",
    "X2 = read_data2(3, img_removed[0]-1)\n",
    "\n",
    "for i in range(nbr-1):\n",
    "    X1 = np.vstack([X1, read_data1(img_removed[i]+1, img_removed[i+1]-1)])\n",
    "\n",
    "for i in range(nbr-1):\n",
    "    X2 = np.vstack([X2, read_data2(img_removed[i]+1, img_removed[i+1]-1)])\n",
    "\n",
    "# Normalize inputs\n",
    "X1 = X1/255\n",
    "X2 = X2/255\n",
    "\n",
    "df = pd.read_excel ('classification.xlsx', engine='openpyxl')\n",
    "# transform categorical to numeric\n",
    "df['Eng'].replace([1,2,3,4],[0, 1, 2, 3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78a4c1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = df['Eng']\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "y = y_all[1:img_removed[0]-1]\n",
    "\n",
    "for i in range(nbr-1):\n",
    "    y = np.hstack([y, y_all[img_removed[i]:img_removed[i+1]-1]])\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05985570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation of data in train-validation-test with rate of 60%-20%-20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1 = preprocess_input(X1)\n",
    "X1_train, X1_test, X2_train, X2_test,y_train, y_test = train_test_split(X1, X2, y, test_size=0.2, shuffle=True, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37f433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    # load the convolutional base model and set layers as not trainable\n",
    "    base_model = BModel(include_top=False, input_shape=IMG_SIZE)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    input1 = Input(IMG_SIZE)\n",
    "    input2 = Input(IMG_SIZE)\n",
    "    \n",
    "    x1 = base_model(input1)\n",
    "    x2 = base_model(input2)\n",
    "    \n",
    "    # add new classifier layers\n",
    "    x1 = layers.Flatten()(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x2 = layers.Flatten()(x2)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    \n",
    "    x = concatenate([x1,x2])\n",
    "\n",
    "    x = layers.Dense(256, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    output = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "    # define new model, compile and fit\n",
    "    model = tensorflow.keras.Model(inputs=[input1,input2], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47a7ef74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 53s 1s/step - loss: 1.9092 - accuracy: 0.2829 - val_loss: 7.1505 - val_accuracy: 0.4950\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.49505, saving model to my_best_model1.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnngo1\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 1.3921 - accuracy: 0.4467 - val_loss: 3.7021 - val_accuracy: 0.5347\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.49505 to 0.53465, saving model to my_best_model1.hdf5\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 416ms/step - loss: 1.1422 - accuracy: 0.4988 - val_loss: 2.5133 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.53465 to 0.55446, saving model to my_best_model1.hdf5\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 1.0223 - accuracy: 0.5633 - val_loss: 1.9865 - val_accuracy: 0.5347\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.55446\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.8955 - accuracy: 0.6476 - val_loss: 1.6970 - val_accuracy: 0.5446\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.55446\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.8594 - accuracy: 0.6526 - val_loss: 1.5117 - val_accuracy: 0.5050\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.55446\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.7052 - accuracy: 0.7221 - val_loss: 1.4555 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.55446\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.6329 - accuracy: 0.7196 - val_loss: 1.4226 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.55446 to 0.56436, saving model to my_best_model1.hdf5\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.5382 - accuracy: 0.8288 - val_loss: 1.3694 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.56436 to 0.57426, saving model to my_best_model1.hdf5\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.4773 - accuracy: 0.8362 - val_loss: 1.3368 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.57426 to 0.58416, saving model to my_best_model1.hdf5\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.3467 - accuracy: 0.9082 - val_loss: 1.3194 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.58416\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.3296 - accuracy: 0.9032 - val_loss: 1.3090 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.58416 to 0.60396, saving model to my_best_model1.hdf5\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 0.3312 - accuracy: 0.8908 - val_loss: 1.3106 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.60396\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.2531 - accuracy: 0.9355 - val_loss: 1.3447 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.60396\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.2737 - accuracy: 0.9156 - val_loss: 1.3867 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.60396\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.2036 - accuracy: 0.9454 - val_loss: 1.3545 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.60396\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.1609 - accuracy: 0.9628 - val_loss: 1.3581 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.60396\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.1396 - accuracy: 0.9752 - val_loss: 1.3778 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.60396\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.1593 - accuracy: 0.9553 - val_loss: 1.4175 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.60396\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1509 - accuracy: 0.9653 - val_loss: 1.4204 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.60396\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.1232 - accuracy: 0.9777 - val_loss: 1.2968 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.60396\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1327 - accuracy: 0.9727 - val_loss: 1.2799 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.60396\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.1326 - accuracy: 0.9677 - val_loss: 1.3007 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.60396\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0998 - accuracy: 0.9926 - val_loss: 1.3349 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.60396\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.1064 - accuracy: 0.9677 - val_loss: 1.4176 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.60396\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1029 - accuracy: 0.9777 - val_loss: 1.4715 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.60396\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.0748 - accuracy: 0.9826 - val_loss: 1.5083 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.60396\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0768 - accuracy: 0.9876 - val_loss: 1.5604 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.60396\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0791 - accuracy: 0.9801 - val_loss: 1.6176 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.60396\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.0738 - accuracy: 0.9876 - val_loss: 1.6288 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.60396\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0603 - accuracy: 0.9901 - val_loss: 1.6233 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.60396\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0747 - accuracy: 0.9826 - val_loss: 1.5951 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.60396\n",
      "*************************\n",
      "Training next model\n",
      "*************************\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 13s 734ms/step - loss: 1.7714 - accuracy: 0.3275 - val_loss: 5.6865 - val_accuracy: 0.4158\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.41584, saving model to my_best_model2.hdf5\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 1.2502 - accuracy: 0.4864 - val_loss: 3.3999 - val_accuracy: 0.3861\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.41584\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.9639 - accuracy: 0.6104 - val_loss: 2.6326 - val_accuracy: 0.3960\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.41584\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.8960 - accuracy: 0.6427 - val_loss: 2.2315 - val_accuracy: 0.3960\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.41584\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.8304 - accuracy: 0.6774 - val_loss: 1.9625 - val_accuracy: 0.4158\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.41584\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.6886 - accuracy: 0.7543 - val_loss: 1.7364 - val_accuracy: 0.4257\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.41584 to 0.42574, saving model to my_best_model2.hdf5\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.5895 - accuracy: 0.8164 - val_loss: 1.6288 - val_accuracy: 0.4455\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.42574 to 0.44554, saving model to my_best_model2.hdf5\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.5495 - accuracy: 0.8288 - val_loss: 1.5512 - val_accuracy: 0.4950\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.44554 to 0.49505, saving model to my_best_model2.hdf5\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 424ms/step - loss: 0.4327 - accuracy: 0.8586 - val_loss: 1.4906 - val_accuracy: 0.5050\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.49505 to 0.50495, saving model to my_best_model2.hdf5\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.4087 - accuracy: 0.8734 - val_loss: 1.4176 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.50495 to 0.52475, saving model to my_best_model2.hdf5\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.3764 - accuracy: 0.8759 - val_loss: 1.3665 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.52475 to 0.57426, saving model to my_best_model2.hdf5\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.2993 - accuracy: 0.9330 - val_loss: 1.3441 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.57426 to 0.60396, saving model to my_best_model2.hdf5\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.2788 - accuracy: 0.9330 - val_loss: 1.3174 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.60396\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.2370 - accuracy: 0.9355 - val_loss: 1.3637 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.60396\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.2101 - accuracy: 0.9380 - val_loss: 1.3874 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.60396\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.2068 - accuracy: 0.9479 - val_loss: 1.3715 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.60396\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.1616 - accuracy: 0.9702 - val_loss: 1.3732 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.60396\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.1400 - accuracy: 0.9702 - val_loss: 1.3940 - val_accuracy: 0.5446\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.60396\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.1221 - accuracy: 0.9826 - val_loss: 1.4411 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.60396\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.1146 - accuracy: 0.9777 - val_loss: 1.4711 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.60396\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1193 - accuracy: 0.9677 - val_loss: 1.4870 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.60396\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.1192 - accuracy: 0.9777 - val_loss: 1.4657 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.60396\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0867 - accuracy: 0.9876 - val_loss: 1.4559 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.60396\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1263 - accuracy: 0.9653 - val_loss: 1.4625 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.60396\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.0930 - accuracy: 0.9727 - val_loss: 1.4904 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.60396\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0851 - accuracy: 0.9801 - val_loss: 1.5641 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.60396\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.1065 - accuracy: 0.9801 - val_loss: 1.5478 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.60396\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0856 - accuracy: 0.9777 - val_loss: 1.4810 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.60396 to 0.61386, saving model to my_best_model2.hdf5\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0732 - accuracy: 0.9826 - val_loss: 1.3938 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.61386\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0621 - accuracy: 0.9876 - val_loss: 1.3620 - val_accuracy: 0.6238\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.61386 to 0.62376, saving model to my_best_model2.hdf5\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.0717 - accuracy: 0.9901 - val_loss: 1.3839 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.62376\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.0669 - accuracy: 0.9801 - val_loss: 1.4119 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.62376\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.0608 - accuracy: 0.9876 - val_loss: 1.4586 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.62376\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.0650 - accuracy: 0.9901 - val_loss: 1.4309 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.62376\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0430 - accuracy: 0.9926 - val_loss: 1.4114 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.62376\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0620 - accuracy: 0.9826 - val_loss: 1.4172 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.62376\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0494 - accuracy: 0.9876 - val_loss: 1.3587 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.62376\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0651 - accuracy: 0.9876 - val_loss: 1.3520 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.62376\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0622 - accuracy: 0.9901 - val_loss: 1.3599 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.62376\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 1.3546 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.62376\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.0499 - accuracy: 0.9876 - val_loss: 1.3511 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.62376\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.0478 - accuracy: 0.9950 - val_loss: 1.3839 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.62376\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0523 - accuracy: 0.9926 - val_loss: 1.4108 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.62376\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0541 - accuracy: 0.9876 - val_loss: 1.4652 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.62376\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0546 - accuracy: 0.9901 - val_loss: 1.5356 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.62376\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0499 - accuracy: 0.9876 - val_loss: 1.5995 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.62376\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0326 - accuracy: 0.9950 - val_loss: 1.6215 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.62376\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0415 - accuracy: 0.9901 - val_loss: 1.6348 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.62376\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0280 - accuracy: 0.9975 - val_loss: 1.6448 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.62376\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.0403 - accuracy: 0.9926 - val_loss: 1.6499 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.62376\n",
      "*************************\n",
      "Training next model\n",
      "*************************\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 13s 746ms/step - loss: 1.9175 - accuracy: 0.2978 - val_loss: 10.9136 - val_accuracy: 0.2970\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.29703, saving model to my_best_model3.hdf5\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 1.3184 - accuracy: 0.4938 - val_loss: 5.1996 - val_accuracy: 0.2871\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.29703\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 1.2426 - accuracy: 0.5236 - val_loss: 3.6444 - val_accuracy: 0.2970\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.29703\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.9013 - accuracy: 0.6179 - val_loss: 2.7582 - val_accuracy: 0.3267\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.29703 to 0.32673, saving model to my_best_model3.hdf5\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.8766 - accuracy: 0.6328 - val_loss: 2.1893 - val_accuracy: 0.3663\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.32673 to 0.36634, saving model to my_best_model3.hdf5\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.7682 - accuracy: 0.7047 - val_loss: 1.8062 - val_accuracy: 0.3663\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.36634\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.6326 - accuracy: 0.7643 - val_loss: 1.6010 - val_accuracy: 0.4356\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.36634 to 0.43564, saving model to my_best_model3.hdf5\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.5400 - accuracy: 0.8139 - val_loss: 1.4786 - val_accuracy: 0.4653\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.43564 to 0.46535, saving model to my_best_model3.hdf5\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.4170 - accuracy: 0.8834 - val_loss: 1.3757 - val_accuracy: 0.5149\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.46535 to 0.51485, saving model to my_best_model3.hdf5\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.4104 - accuracy: 0.8586 - val_loss: 1.2804 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.51485 to 0.56436, saving model to my_best_model3.hdf5\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.3791 - accuracy: 0.8809 - val_loss: 1.2211 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56436\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.2982 - accuracy: 0.9156 - val_loss: 1.2234 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.56436 to 0.57426, saving model to my_best_model3.hdf5\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.2902 - accuracy: 0.9181 - val_loss: 1.2365 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.57426 to 0.58416, saving model to my_best_model3.hdf5\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.2432 - accuracy: 0.9479 - val_loss: 1.2395 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.58416\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.2124 - accuracy: 0.9553 - val_loss: 1.2532 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.58416\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.1888 - accuracy: 0.9380 - val_loss: 1.2536 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.58416 to 0.59406, saving model to my_best_model3.hdf5\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.1509 - accuracy: 0.9702 - val_loss: 1.2790 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.59406 to 0.60396, saving model to my_best_model3.hdf5\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1666 - accuracy: 0.9578 - val_loss: 1.2867 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.60396\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.1289 - accuracy: 0.9677 - val_loss: 1.2840 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.60396\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.1158 - accuracy: 0.9752 - val_loss: 1.2902 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.60396 to 0.61386, saving model to my_best_model3.hdf5\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1371 - accuracy: 0.9578 - val_loss: 1.3294 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.61386\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.1027 - accuracy: 0.9777 - val_loss: 1.3522 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.61386\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.1032 - accuracy: 0.9801 - val_loss: 1.3742 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.61386\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0921 - accuracy: 0.9801 - val_loss: 1.3913 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.61386\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.1246 - accuracy: 0.9702 - val_loss: 1.4021 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.61386\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.0793 - accuracy: 0.9876 - val_loss: 1.4016 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.61386\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0915 - accuracy: 0.9752 - val_loss: 1.4250 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.61386\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0674 - accuracy: 0.9876 - val_loss: 1.4153 - val_accuracy: 0.6238\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.61386 to 0.62376, saving model to my_best_model3.hdf5\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0556 - accuracy: 0.9926 - val_loss: 1.4288 - val_accuracy: 0.6238\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.62376\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.0776 - accuracy: 0.9826 - val_loss: 1.4633 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.62376\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0467 - accuracy: 0.9926 - val_loss: 1.5243 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.62376\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.0678 - accuracy: 0.9876 - val_loss: 1.5343 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.62376\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.0650 - accuracy: 0.9851 - val_loss: 1.5131 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.62376\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0602 - accuracy: 0.9851 - val_loss: 1.4819 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.62376\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0387 - accuracy: 0.9926 - val_loss: 1.4600 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.62376\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.0487 - accuracy: 0.9901 - val_loss: 1.4719 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.62376\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0397 - accuracy: 0.9950 - val_loss: 1.5091 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.62376\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.0485 - accuracy: 0.9950 - val_loss: 1.6669 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.62376\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.0554 - accuracy: 0.9851 - val_loss: 1.6690 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.62376\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0529 - accuracy: 0.9876 - val_loss: 1.6174 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.62376\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0376 - accuracy: 0.9926 - val_loss: 1.5656 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.62376\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0344 - accuracy: 0.9975 - val_loss: 1.5389 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.62376\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0475 - accuracy: 0.9950 - val_loss: 1.5861 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.62376\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.0367 - accuracy: 0.9926 - val_loss: 1.6160 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.62376\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.0401 - accuracy: 0.9950 - val_loss: 1.5767 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.62376\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.0456 - accuracy: 0.9876 - val_loss: 1.4348 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.62376\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0326 - accuracy: 0.9975 - val_loss: 1.3872 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.62376\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.0363 - accuracy: 0.9975 - val_loss: 1.3927 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.62376\n",
      "*************************\n",
      "Training next model\n",
      "*************************\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 13s 739ms/step - loss: 1.8476 - accuracy: 0.2804 - val_loss: 10.1676 - val_accuracy: 0.4554\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.45545, saving model to my_best_model4.hdf5\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 1.3481 - accuracy: 0.4218 - val_loss: 4.7289 - val_accuracy: 0.4356\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.45545\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 1.1249 - accuracy: 0.5310 - val_loss: 2.9420 - val_accuracy: 0.4752\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.45545 to 0.47525, saving model to my_best_model4.hdf5\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 1.0447 - accuracy: 0.5608 - val_loss: 2.2304 - val_accuracy: 0.5149\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.47525 to 0.51485, saving model to my_best_model4.hdf5\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.8959 - accuracy: 0.6452 - val_loss: 1.8923 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.51485 to 0.52475, saving model to my_best_model4.hdf5\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.8008 - accuracy: 0.6923 - val_loss: 1.6919 - val_accuracy: 0.5347\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.52475 to 0.53465, saving model to my_best_model4.hdf5\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.6544 - accuracy: 0.7742 - val_loss: 1.5897 - val_accuracy: 0.5347\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53465\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.6030 - accuracy: 0.7742 - val_loss: 1.5049 - val_accuracy: 0.5446\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.53465 to 0.54455, saving model to my_best_model4.hdf5\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.5468 - accuracy: 0.8139 - val_loss: 1.4605 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.54455 to 0.56436, saving model to my_best_model4.hdf5\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.4534 - accuracy: 0.8437 - val_loss: 1.4164 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56436\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.4155 - accuracy: 0.8734 - val_loss: 1.3565 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.56436 to 0.59406, saving model to my_best_model4.hdf5\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.3258 - accuracy: 0.9082 - val_loss: 1.3328 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.59406 to 0.61386, saving model to my_best_model4.hdf5\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.3230 - accuracy: 0.8958 - val_loss: 1.3021 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.61386\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.2973 - accuracy: 0.9132 - val_loss: 1.3149 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.61386\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.2804 - accuracy: 0.9132 - val_loss: 1.3292 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.61386\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.2258 - accuracy: 0.9355 - val_loss: 1.3467 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.61386\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.1609 - accuracy: 0.9702 - val_loss: 1.3416 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.61386\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.1661 - accuracy: 0.9628 - val_loss: 1.3505 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.61386\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.1610 - accuracy: 0.9628 - val_loss: 1.3422 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.61386\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.1624 - accuracy: 0.9454 - val_loss: 1.3295 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.61386\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.1252 - accuracy: 0.9752 - val_loss: 1.3148 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.61386\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.1312 - accuracy: 0.9702 - val_loss: 1.3202 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.61386\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.1196 - accuracy: 0.9752 - val_loss: 1.3134 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.61386\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1320 - accuracy: 0.9603 - val_loss: 1.2969 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.61386\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.1026 - accuracy: 0.9752 - val_loss: 1.2969 - val_accuracy: 0.6238\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.61386 to 0.62376, saving model to my_best_model4.hdf5\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.1084 - accuracy: 0.9727 - val_loss: 1.3174 - val_accuracy: 0.6238\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.62376\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0964 - accuracy: 0.9777 - val_loss: 1.3203 - val_accuracy: 0.6238\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.62376\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0738 - accuracy: 0.9901 - val_loss: 1.3219 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.62376\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0678 - accuracy: 0.9901 - val_loss: 1.3666 - val_accuracy: 0.6238\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.62376\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0864 - accuracy: 0.9801 - val_loss: 1.3973 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.62376\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0652 - accuracy: 0.9901 - val_loss: 1.4151 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.62376\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0617 - accuracy: 0.9901 - val_loss: 1.4425 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.62376\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0770 - accuracy: 0.9851 - val_loss: 1.4500 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.62376\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0626 - accuracy: 0.9826 - val_loss: 1.4330 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.62376\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0481 - accuracy: 0.9926 - val_loss: 1.4441 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.62376\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0614 - accuracy: 0.9851 - val_loss: 1.4452 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.62376\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0502 - accuracy: 0.9975 - val_loss: 1.4292 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.62376\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0464 - accuracy: 0.9950 - val_loss: 1.4024 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.62376\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0416 - accuracy: 0.9926 - val_loss: 1.3934 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.62376\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.0423 - accuracy: 0.9901 - val_loss: 1.3897 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.62376\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0496 - accuracy: 0.9926 - val_loss: 1.3758 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.62376\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0569 - accuracy: 0.9901 - val_loss: 1.3762 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.62376\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.0510 - accuracy: 0.9901 - val_loss: 1.3846 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.62376\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0394 - accuracy: 0.9975 - val_loss: 1.3773 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.62376\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.0362 - accuracy: 0.9926 - val_loss: 1.3395 - val_accuracy: 0.6436\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.62376 to 0.64356, saving model to my_best_model4.hdf5\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0427 - accuracy: 0.9926 - val_loss: 1.3614 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.64356\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0503 - accuracy: 0.9876 - val_loss: 1.3802 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.64356\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0408 - accuracy: 0.9950 - val_loss: 1.3890 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.64356\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0344 - accuracy: 0.9950 - val_loss: 1.4102 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.64356\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.0330 - accuracy: 0.9926 - val_loss: 1.4189 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.64356\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0340 - accuracy: 0.9975 - val_loss: 1.4234 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.64356\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0350 - accuracy: 0.9950 - val_loss: 1.4459 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.64356\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0379 - accuracy: 0.9876 - val_loss: 1.4563 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.64356\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0280 - accuracy: 0.9950 - val_loss: 1.4677 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.64356\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0435 - accuracy: 0.9851 - val_loss: 1.4768 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.64356\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0342 - accuracy: 0.9901 - val_loss: 1.5064 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.64356\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0265 - accuracy: 0.9950 - val_loss: 1.5283 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.64356\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0243 - accuracy: 0.9975 - val_loss: 1.5498 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.64356\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0233 - accuracy: 0.9975 - val_loss: 1.5653 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.64356\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0306 - accuracy: 0.9950 - val_loss: 1.5728 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.64356\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0323 - accuracy: 0.9926 - val_loss: 1.5672 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.64356\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.5597 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.64356\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 1.5552 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.64356\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 1.5535 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.64356\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.5508 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.64356\n",
      "*************************\n",
      "Training next model\n",
      "*************************\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 14s 958ms/step - loss: 1.7978 - accuracy: 0.2822 - val_loss: 9.1603 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59000, saving model to my_best_model5.hdf5\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 1.2974 - accuracy: 0.4629 - val_loss: 4.5159 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.59000 to 0.61000, saving model to my_best_model5.hdf5\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 1.1337 - accuracy: 0.5371 - val_loss: 3.0692 - val_accuracy: 0.5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.61000\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.9495 - accuracy: 0.5842 - val_loss: 2.3669 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.61000\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.9725 - accuracy: 0.6064 - val_loss: 1.9599 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.61000\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.7976 - accuracy: 0.6881 - val_loss: 1.7710 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.61000\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.6547 - accuracy: 0.7624 - val_loss: 1.6407 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.61000\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.6162 - accuracy: 0.7847 - val_loss: 1.5090 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.61000\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.5034 - accuracy: 0.8267 - val_loss: 1.4545 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.61000 to 0.63000, saving model to my_best_model5.hdf5\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.4153 - accuracy: 0.8688 - val_loss: 1.4443 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.63000\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.3693 - accuracy: 0.8762 - val_loss: 1.4226 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.63000\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.2786 - accuracy: 0.9332 - val_loss: 1.4182 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.63000\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.3156 - accuracy: 0.8960 - val_loss: 1.4046 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.63000\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.2833 - accuracy: 0.9233 - val_loss: 1.4050 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.63000\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.2586 - accuracy: 0.9406 - val_loss: 1.4286 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.63000\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.2093 - accuracy: 0.9579 - val_loss: 1.4526 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.63000\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.2221 - accuracy: 0.9282 - val_loss: 1.4465 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.63000\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.1859 - accuracy: 0.9629 - val_loss: 1.4542 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.63000\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.1638 - accuracy: 0.9554 - val_loss: 1.4427 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.63000 to 0.64000, saving model to my_best_model5.hdf5\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.1700 - accuracy: 0.9629 - val_loss: 1.5110 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64000\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.1232 - accuracy: 0.9752 - val_loss: 1.5981 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64000\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.1405 - accuracy: 0.9604 - val_loss: 1.6164 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.64000\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0977 - accuracy: 0.9802 - val_loss: 1.5701 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.64000\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0997 - accuracy: 0.9827 - val_loss: 1.5119 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.64000\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0950 - accuracy: 0.9851 - val_loss: 1.4689 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.64000\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.1025 - accuracy: 0.9777 - val_loss: 1.5010 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.64000\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0907 - accuracy: 0.9777 - val_loss: 1.5513 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.64000\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.0783 - accuracy: 0.9827 - val_loss: 1.5115 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.64000\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0847 - accuracy: 0.9827 - val_loss: 1.5197 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.64000\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0635 - accuracy: 0.9926 - val_loss: 1.7810 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.64000\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0545 - accuracy: 0.9950 - val_loss: 1.8715 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.64000\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0758 - accuracy: 0.9851 - val_loss: 1.8125 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.64000\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.0862 - accuracy: 0.9728 - val_loss: 1.7094 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.64000\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0681 - accuracy: 0.9876 - val_loss: 1.6398 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64000\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0562 - accuracy: 0.9901 - val_loss: 1.6209 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.64000\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0449 - accuracy: 0.9950 - val_loss: 1.6146 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.64000\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0772 - accuracy: 0.9752 - val_loss: 1.5946 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.64000\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.0598 - accuracy: 0.9827 - val_loss: 1.5652 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.64000\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0529 - accuracy: 0.9851 - val_loss: 1.5904 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.64000\n",
      "*************************\n",
      "Training next model\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "# store the trained models in a list\n",
    "list_of_models = []\n",
    "list_of_histories = []\n",
    "count = 0\n",
    "\n",
    "# we use k-Fold (i.e. we will build k models)\n",
    "kfold = StratifiedKFold(n_splits=N_Fold, shuffle=True, random_state=0)\n",
    "\n",
    "                                    #pourquoi X1_train ici\n",
    "for train_index, val_index in kfold.split(X1_train,y_train): \n",
    "    count = count + 1\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor = \"val_accuracy\",patience = 20),\n",
    "        ModelCheckpoint(\n",
    "        filepath = 'my_best_model'+str(count)+'.hdf5',\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1)\n",
    "    ]\n",
    "\n",
    "    model = create_model()\n",
    "    \n",
    "    # building the models\n",
    "    history=model.fit([X1_train[train_index],X2_train[train_index]],y_train[train_index],epochs=100, batch_size = 64,\n",
    "                   callbacks=callbacks,\n",
    "                   validation_data = ([X1_train[val_index],X2_train[val_index]],y_train[val_index]))\n",
    "                                                            #pourquoi X1_train\n",
    "    list_of_models.append(model)\n",
    "    list_of_histories.append(history)\n",
    "    print('*************************')\n",
    "    print('Training next model')\n",
    "    print('*************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21cec0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtHUlEQVR4nO3deZhU1bX38e+iERFBUECDgICKQbjI1JKIRDFoxCESHEFMRJIgqDHDqxFDHK65vDeJ3ji8MSZ4nSXgCCEGNYIak5hEGgQUnBBB2gEZlCHI2Ov9Y59uiqKm7qrqqq7+fZ6nnq4zrzrdvWqfffbZ29wdERFp+JoUOgAREckNJXQRkRKhhC4iUiKU0EVESoQSuohIiVBCFxEpEUroJczMnjazi3O9biGZ2QozOzkP+3UzOzJ6/1szuy6TdetwnNFm9ue6ximSiqkdenExs80xky2AbcCuaPpSd59a/1EVDzNbAXzH3efkeL8OdHf3Zbla18y6Au8B+7j7zpwEKpJC00IHIHty95bV71MlLzNrqiQhxUJ/j8VBVS4NhJkNMbNKM7vGzD4G7jOzA83sKTNbY2afRu87xWzzopl9J3o/xsz+Zma3ROu+Z2an1XHdbmb2kpltMrM5ZnanmT2cJO5MYvyZmf092t+fzaxdzPJvmtlKM1tnZpNSnJ8vm9nHZlYWM2+EmS2O3g80s3+Y2Wdm9pGZ/drMmiXZ1/1m9l8x01dH23xoZmPj1j3DzF41s41mtsrMboxZ/FL08zMz22xmx1Wf25jtB5nZPDPbEP0clOm5qeV5PsjM7os+w6dmNjNm2XAzWxh9hnfNbFg0f4/qLTO7sfr3bGZdo6qnb5vZ+8Dz0fzHot/DhuhvpFfM9vuZ2f9Ev88N0d/Yfmb2JzP7XtznWWxm30j0WSU5JfSG5QvAQUAXYBzh93dfNH0Y8Dnw6xTbfwl4C2gH/BK4x8ysDuv+HngFaAvcCHwzxTEzifFC4BLgYKAZcBWAmfUE7or2f2h0vE4k4O7/BP4NfDVuv7+P3u8Cfhh9nuOAocBlKeImimFYFM8pQHcgvv7+38C3gDbAGcCEmER0QvSzjbu3dPd/xO37IOBPwB3RZ/sV8Cczaxv3GfY6NwmkO88PEarwekX7ujWKYSDwIHB19BlOAFYkOUYiJwJHA6dG008TztPBwAIgtorwFmAAMIjwd/xjoAp4ALioeiUz6wN0BGbXIg4BcHe9ivRF+Mc6OXo/BNgONE+xfl/g05jpFwlVNgBjgGUxy1oADnyhNusSksVOoEXM8oeBhzP8TIli/GnM9GXAM9H764HpMcv2j87ByUn2/V/AvdH7VoRk2yXJuj8AZsRMO3Bk9P5+4L+i9/cCP49Z76jYdRPs9zbg1uh912jdpjHLxwB/i95/E3glbvt/AGPSnZvanGegAyFxHphgvd9Vx5vq7y+avrH69xzz2Q5PEUObaJ3WhC+cz4E+CdbbF1hPuC8BIfH/Jh//U6X+Ugm9YVnj7lurJ8yshZn9LrqE3Ui4xG8TW+0Q5+PqN+6+JXrbspbrHgqsj5kHsCpZwBnG+HHM+y0xMR0au293/zewLtmxCKXxs81sX+BsYIG7r4ziOCqqhvg4iuP/Ekrr6ewRA7Ay7vN9ycxeiKo6NgDjM9xv9b5Xxs1bSSidVkt2bvaQ5jx3JvzOPk2waWfg3QzjTaTm3JhZmZn9PKq22cjukn676NU80bHcfRvwKHCRmTUBRhGuKKSWlNAblvgmSf8H+CLwJXc/gN2X+MmqUXLhI+AgM2sRM69zivWzifGj2H1Hx2ybbGV3X0pIiKexZ3ULhKqbNwmlwAOAn9QlBsIVSqzfA7OAzu7eGvhtzH7TNSH7kFBFEusw4IMM4oqX6jyvIvzO2iTYbhVwRJJ9/ptwdVbtCwnWif2MFwLDCdVSrQml+OoY1gJbUxzrAWA0oSpsi8dVT0lmlNAbtlaEy9jPovrYG/J9wKjEWwHcaGbNzOw44Ot5ivFx4EwzGxzdwLyJ9H+zvweuJCS0x+Li2AhsNrMewIQMY3gUGGNmPaMvlPj4WxFKv1uj+ugLY5atIVR1HJ5k37OBo8zsQjNramYXAD2BpzKMLT6OhOfZ3T8i1G3/Jrp5uo+ZVSf8e4BLzGyomTUxs47R+QFYCIyM1i8Hzs0ghm2Eq6gWhKug6hiqCNVXvzKzQ6PS/HHR1RRRAq8C/geVzutMCb1huw3Yj1D6+SfwTD0ddzThxuI6Qr31I4R/5ERuo44xuvsS4HJCkv4I+BSoTLPZNML9hufdfW3M/KsIyXYTcHcUcyYxPB19hueBZdHPWJcBN5nZJkKd/6Mx224BJgN/t9C65stx+14HnEkoXa8j3CQ8My7uTN1G6vP8TWAH4SrlE8I9BNz9FcJN11uBDcBf2H3VcB2hRP0p8J/secWTyIOEK6QPgKVRHLGuAl4D5hHqzH/BnjnoQaA34Z6M1IEeLJKsmdkjwJvunvcrBCldZvYtYJy7Dy50LA2VSuhSa2Z2rJkdEV2iDyPUm84scFjSgEXVWZcBUwodS0OmhC518QVCk7rNhDbUE9z91YJGJA2WmZ1KuN+wmvTVOpKCqlxEREqESugiIiWiYJ1ztWvXzrt27Vqow4uINEjz589f6+7tEy0rWELv2rUrFRUVhTq8iEiDZGbxTxfXUJWLiEiJUEIXESkRSugiIiVCCV1EpESkTehmdq+ZfWJmrydZbmZ2h5kti0YZ6Z/7MEVEJJ1MSuj3A8NSLD+NMEJJd8IoOndlH5aIlKKpU6FrV2jSJPycWmRDnhd7fOmkTeju/hKhZ7RkhgMPevBPQqf6HXIVoIg0HKkS4tSpMG4crFwJ7uHnuHHFkzSLPb5M5KIOvSN7juhSyZ4jrtQws3FmVmFmFWvWrMnBoUWkWKRLiJMmwZYte26zZUuYn8sYUpWwUy2vj/jyLpNx6ggjj7yeZNmfgMEx03OBAen2OWDAABeR2nn4YfcuXdzNws+HHy50RLt16eIeUvmery5dwnKzxMvNdu8jm8/38MPuLVrsue8WLXbvI93yTOLLVi5+f0CFJ8vVyRbssVLqhP47YFTM9FtAh3T7VEKXxijdP3Sq5ekSUqHjS5cQ0yX8bD9fuv1nuzzb85er31++E/oZhOGtDPgycaOYJ3spoUtjk20JMpOEk88vjGzjy8XnSyXdF0q65dkm3Hx/vmpZJXTCkF4fEYavqgS+TRjZfHy03IA7CaN5vwaUp9unK6FLA5XNJXO2JcRsE1K2CScXJexsSvjpts9FCTybL8RcVDllIusSej5eSujS0GRbgsu2BJnvKoVs46s+R/n6wsv2CyvfJfBsf3+ZUkIXyYFs/yHzXQIu9BdGtgpd5ZROfVzBZEIJXRqNbFsRZFslkG7f2ZYg81nlkO8SbqbnKF/nP1u5qIMvilYu+XgpoUuuFcNNrWxLiIVstpfv+LKV7yuEXBy/Ps6PEro0GPm8JE63/4ZQgk2nmBNytgp9fgt9/GpK6NIg5PumY7Z10NX7qOsXgmSv0F9IhT6+e+qEbmF5/SsvL3cNQSexunYNj4vH69IFVqzIfvtsl6fTpElI4fHMoKoq/fYimTCz+e5enmiZ+kOXovH++7WbH2/yZGjRYs95LVqE+ZnsP9326Rx2WO3mi+SaErrUq1SdI2WbEEePhilTQonaLPycMiXMz2T/6bZPJ9svBJGsJauLyfdLdeiNT6FvKha62Z1ILqCbopKpfCakYmj2pYQrDV2qhK6bolKjuj/r2D6hW7SoXbVDKrppKJI93RSVjOS7g/9c3DRs6EOEieSTErrUyLaVCaROuNneNCyFIcJE8kkJXWpkW4JOl3CzbUVSEkOEieSR6tClRrZ16Nk+mJOO6uBFVIcuGcq2BJ2LKptU9OCOSGpK6LKH0aNDabqqKvysTeuWfCdcPbgjkpoSuuRMvhNutlcQIqUuo4RuZsPM7C0zW2ZmExMsP9DMZpjZYjN7xcz+I/ehSrGrj4SbzRWESKlrmm4FMysjDAJ9CmGQ6HlmNsvdl8as9hNgobuPMLMe0fpD8xGwFLfRo5VkRQolkxL6QGCZuy939+3AdGB43Do9gbkA7v4m0NXMDslppFIU9GCPSPHKJKF3BFbFTFdG82ItAs4GMLOBQBegUy4ClOKhB3tEilsmCd0SzItvDfxz4EAzWwh8D3gV2LnXjszGmVmFmVWsWbOmtrFKgenBHpHilrYOnVAi7xwz3Qn4MHYFd98IXAJgZga8F72IW28KMAXCg0V1C1kKJd/tzEUkO5mU0OcB3c2sm5k1A0YCs2JXMLM20TKA7wAvRUleSoge7BEpbmkTurvvBK4AngXeAB519yVmNt7MxkerHQ0sMbM3gdOA7+crYMlONjc19WCPSHHLpMoFd58NzI6b99uY9/8Auuc2NMm1+L5aqm9qQmZNDavXmTQpVLMcdlhI5mqmKFIc9KRoiUlVAs/FTU092CNSvDIqoUvDkK4ErpuaIqVNJfQSkq4ErpuaIqVNCb2EpCuB66amSGlTQi8h6Urg6q1QpLQpoZeQTErguqkpUrqU0EuISuAijZtauZQYdV8r0niphC4iUiKU0EVESoQSuohIiVBCFxEpEUroDYiGfxORVNTKpYHItqdEESl9KqE3EBr+TUTSUUJvINRTooiko4TeQKinRBFJRwm9gVBPiSKSjhJ6A6F+WkQknYwSupkNM7O3zGyZmU1MsLy1mf3RzBaZ2RIzuyT3oYp6ShSRVNImdDMrA+4ETgN6AqPMrGfcapcDS929DzAE+B8za5bjWEVEJIVMSugDgWXuvtzdtwPTgeFx6zjQyswMaAmsB3bmNFIREUkpk4TeEVgVM10ZzYv1a+Bo4EPgNeD77l4VvyMzG2dmFWZWsWbNmjqGLCIiiWSS0C3BPI+bPhVYCBwK9AV+bWYH7LWR+xR3L3f38vbt29cyVBERSSWThF4JdI6Z7kQoice6BHjSg2XAe0CP3ITYeKivFhHJRiYJfR7Q3cy6RTc6RwKz4tZ5HxgKYGaHAF8Elucy0FJX3VfLypXgvruvFiV1EclU2oTu7juBK4BngTeAR919iZmNN7Px0Wo/AwaZ2WvAXOAad1+br6BLkfpqEZFsmXt8dXj9KC8v94qKioIcuxg1aRJK5vHMQrtzEREAM5vv7uWJlulJ0SKhvlpEJFtK6EVCfbWISLaU0OtRqlYs6qtFRLKlEYvqSSYjDo0erQQuInWnEno9USsWEck3JfR6ohGHRCTflNDriVqxiEi+KaHXE7ViEZF8U0KvJ2rFIiL5plYu9UitWEQkn1RCFxEpEUroIiIlQgldRKREKKGLiJQIJXQRkRKhhC4iUiKU0EVESoQSuohIiVBCFxEpERkldDMbZmZvmdkyM5uYYPnVZrYwer1uZrvM7KDchysiIsmkTehmVgbcCZwG9ARGmVnP2HXc/WZ37+vufYFrgb+4+/o8xCsiIklkUkIfCCxz9+Xuvh2YDgxPsf4oYFoughMRkcxlktA7AqtipiujeXsxsxbAMOCJJMvHmVmFmVWsWbOmtrEWvVRjhoqI5FsmCd0SzPMk634d+Huy6hZ3n+Lu5e5e3r59+0xjbBCqxwxduRLcd48ZqqQuIvUlk4ReCXSOme4EfJhk3ZE00uoWjRkqIoWWSUKfB3Q3s25m1oyQtGfFr2RmrYETgT/kNsSGQWOGikihpU3o7r4TuAJ4FngDeNTdl5jZeDMbH7PqCODP7v7v/IRa3DRmqIgUWkYjFrn7bGB23Lzfxk3fD9yfq8AamsmTQ515bLWLxgwVkfqkJ0VzRGOGikihaUzRHNKYoSJSSCqhi4iUCCV0EZESoYQuIlIilNBFREqEErqISIlQQhcRKRFK6CIiJULt0KXRcQ8PfxWrbOPbti28kmnSBFq2rPv+pXiphC6NwmefwX33wamnhi4ZJkyAfxdZr0NVVXD77dC6NQwYALfcAqtWpd8OYPPm0FXz178OrVqFfSR7tWoFffvCL34RunmW0mHuybo2z6/y8nKvqKgoyLGlcdiyBf74R5g+HWbPhu3b4fDDQ7J8/HE48kh48EH48pcLHWlI3JdcAnPnwtChsGkTvPJKWDZ4MIwcCeedBwcfvHubrVvh6adh2jR46in4/HPo1Cms16lT8mNt2QJ/+hP8859h+rjjYNQoOP98OOSQ/H1GyQ0zm+/u5QmXKaE3LO4wfz706gX77Vf77T//HBYtgj596rZ9Otu2wauvQu/esP/+ddv+n/8McdbVxo0wcybMmhVK4R06wAUXhKR17LGhOuMvf4GLLw6J9Cc/geuvh332qfsx68odfv97uPxy2LkTbr0VvvOdEOO778Ijj4SE/frroapk6FA466zwN/Dkk+Gztm8fkvioUTBoUFgvE++9t3v/ixeH7U46Kezn7LPhwAPz+9mlblIldNy9IK8BAwa41N7dd7uDe6tW7t/8pvvs2e7bt6feZvv2sN63vhW2A/eWLd0vusj9qafct23LLqYdO9yffdZ9zBj31q3D/vff333UKPdZs9Lvf8cO9+eecx871r1Nm7B9tq+2bd0vvdT9hRfcd+5MfNwNG0LM4N6/v/uSJdmdh9pau9b9vPPC8QcNcl+2LPm6r73mPmmS++GHh/Vbt3a/5JJw3nfsyD6WJUvcr7vO/cgjw/732cf96193//3v3Tdtyn7/kjtAhSfJqyqhNyAbNkD37qEnxz594IknQt1w27Zw7rmhZPWVr4SSVlUV/PWvobrh8cdh7Vpo0yaUvIYOhRdfDPM//RQOOgjOOSdsf8IJUFaWPpaqKnj55VC6e+wxWLMGDjgg7P+UU+Cll8L+160Lx63e/5AhYf9VVfCPf4T4Hn0UPvkk1O2OGBE+SzYjFDZtGs5PpiXuGTNC18ebNsHPfw5XXpl5KbeunnkGxo4Nv5ebboKrr87svLvDO++EfvabN899XNVXgNOnh9J7ZWW45/D1r4ff37BhsO++uT+uZE5VLiXiqqvgV7+CefNCPfD27fDssyGp/uEPoW700EPDZfOLL8IHH4R/xuHDQx3sqafu+c+4fTv8+c/hn3fmzN3VEyNGhC+JZD77LKy/alWoton9Z49NMjt2wJw5Ib6ZM0PCPOQQOPnk8GXz/vth/TPPDNufdlp+qoEy8fHH8N3vhrroIUPCF2O+vPcePPxwqDZ7+OFwg7IYVVXB3/+++0t77dpwU/Ub30g9cItZqPoZOjR8uTYmK1eGAsL6hKMq7zZ4MHzta3U7hqpcSsCbb7o3ber+7W8nXr55s/v06e7Dh7sfeGD4OW1amJ+Jf//b/dFH3UeMcG/e3N0s+Wvffd3PPNN96tTML8e3bHF//HH3c891P+gg99NPd3/oIfeNGzPbvj5UVblPmRKqfVJ9/mxfzZq5/+hH7p9/XuhPnLkdO9yfeSZUUaU7P9XVXu3auU+Y4P7SS+67dhX6E+TPxx+733FHqDar/uzp/gYmTqz78VCVS25MnRoGfX7//VBCmTy5/vo/P/PMUI3xzjtqiSDFbevWUKU0bVpoZVTd+qb6xnT//sX9HEAmPv00lMSnTYPnnw9XM717hyvhkSNDa6p8aVRVLnPmwD33wMSJoR41V6ZOTTzEXH2MSvT003D66XDzzaHaRaSh2Lw5tDaaNi1UD+7YEZqLdulS6Mjqbvt2+Ne/ws8jjghfUiNHhiq0+pB1QjezYcDtQBnwv+7+8wTrDAFuA/YB1rr7ian2meuEvmVLSOL/7/+Fb/+mTeFnPwsJMJObTel07Zr4IYwuXWDFiuz3n8yOHeGbv6oqNF1r1ix/xxLJp/XrQ1PLGTPCDf6Gyiw0fx01CsrL6/9qI6s6dEISfxc4HGgGLAJ6xq3TBlgKHBZNH5xuv7msQ583z71Hj1B3deWV7u+/H+pqwX3wYPfly7M/RmzdYOzLLPt9p3LrreE4f/xjfo8jIg0DKerQM2mcNRBY5u7L3X07MB0YHrfOhcCT7v5+9CXxSW2+cepq585QCj/uuNCC4rnnwqPTnTuHpnAPPRQemDjmmFANk03tUrK7+qnu9mdrzRq48cbQOuWMM/J3HBEpDZkk9I5AbI8SldG8WEcBB5rZi2Y238y+lWhHZjbOzCrMrGLNmjV1izjy9tuh6c/114dHll97LTSH230suOiiMP/YY8PTd8OHw+rVdTve5MmhzjxWixZhfr5cd12og7z11oZ/E0lE8i+ThJ4olcSXdZsCA4AzgFOB68zsqL02cp/i7uXuXt6+jk+OuMNdd4W2u2+/HdpQT52a/DHlww4LN0pvvTW0ue7dO7TZTmTq1FBX3qRJ+Dl16u5lo0eHG6DVJfIOHcIj4z17hkfdY19vvJHd1QDAwoXheFdcAUcfnd2+RKSRSFYXU/0CjgOejZm+Frg2bp2JwI0x0/cA56Xab13r0KsffT/1VPfKytptu2RJeMQbwmPmGzbsXvbww+4tWuxZP96iRZhfbfVq97POSlyXHv/q0sX9mmvcFy4M7Ztro6rK/cQTw+Pr69fXblsRKW1k0w7dzJoCbwNDgQ+AecCF7r4kZp2jgV8TSufNgFeAke7+erL91rWVy7ZtoX78oovqVg2xfXt41Pq//zuUth98MDwVmK4Vyx/+EJ4k3LgxVPOkaqK0dm14LP/Pf4Zdu6BHj91Nm47a67plb48/HjpbuusuGD++9p9RREpXLpotnk5oklgG3Ovuk81sPIC7/zZa52rgEqCK0LTxtlT7LPSDRf/4B3zrW6FHu6uuCm28kxk7Fu69F/r1CzdaM21vWp3Yp00LDwW5h4cqRoxI3ZPdzTeHR6wXLMhNk0sRKR2N6sGi2ti8OSTz3/0udOS0Y8fe65SVhUR87bWhZF7XduAffBCuLKZNC32xpLLffuFhohNTtuQXkcZICT2N2bPhwgsTP+xw8MHhQYhBg3J3vM8+S/zlUW2//TREmIgkliqhN7K+0BI7/XRYtiz8jC09f/Wroe4818m1TZvc7k9EBDSmaI127UL/DNVDkj31VBgOTCVlEWkoVEKPYQbf/GZ4iYg0NCqhi4iUCCV0EZESoYQuIlIilNBFREpEo0roqTrfEhFp6BpNK5f4IeRWrgzTUH/jgoqI5FOjKaFPmrTneKAQpidNKkw8IiK51mgS+vvv126+iEhD02gSeiGGkBMRqU+NJqEXYgg5EZH61GgSevUQcl26hEf8u3QJ07ohKiKlotG0coGQvJXARaRUNZoSuohIqVNCFxEpERkldDMbZmZvmdkyM5uYYPkQM9tgZguj1/W5D1VERFJJW4duZmXAncApQCUwz8xmufvSuFX/6u5n5iFGERHJQCYl9IHAMndf7u7bgenA8PyGJSIitZVJQu8IrIqZrozmxTvOzBaZ2dNm1isn0YmISMYyabZoCeZ53PQCoIu7bzaz04GZQPe9dmQ2DhgHcJge0RQRyalMSuiVQOeY6U7Ah7EruPtGd98cvZ8N7GNm7eJ35O5T3L3c3cvbt2+fRdgiIhIvk4Q+D+huZt3MrBkwEpgVu4KZfcHMLHo/MNrvulwHKyIiyaWtcnH3nWZ2BfAsUAbc6+5LzGx8tPy3wLnABDPbCXwOjHT3+GoZERHJIytU3i0vL/eKioqCHFtEpKEys/nuXp5omZ4UFREpEUroIiIloqQSugaBFpHGrGS6z9Ug0CLS2JVMCV2DQItIY1cyCV2DQItIY1cyCV2DQItIY1cyCV2DQItIY1cyCV2DQItIY1cyrVxAg0CLSONWMiV0EZHGTgldRKREKKGLiJQIJXQRkRKhhC4iUiKU0EVESoQSuohIiVBCFxEpEUroIiIlIqOEbmbDzOwtM1tmZhNTrHesme0ys3NzF6KIiGQibUI3szLgTuA0oCcwysx6JlnvF8CzuQ5SRETSy6SEPhBY5u7L3X07MB0YnmC97wFPAJ/kMD4REclQJgm9I7AqZroymlfDzDoCI4DfptqRmY0zswozq1izZk1tYxURkRQySeiWYJ7HTd8GXOPuu1LtyN2nuHu5u5e3b98+wxBFRCQTmXSfWwl0jpnuBHwYt045MN3MANoBp5vZTnefmYsgRUQkvUwS+jygu5l1Az4ARgIXxq7g7t2q35vZ/cBTSuYiIvUrbUJ3951mdgWh9UoZcK+7LzGz8dHylPXmIiJSPzIascjdZwOz4+YlTOTuPib7sEQalx07dlBZWcnWrVsLHYoUiebNm9OpUyf22WefjLcpqSHoRBqqyspKWrVqRdeuXYnuRUkj5u6sW7eOyspKunXrln6DiB79FykCW7dupW3btkrmAoCZ0bZt21pfsSmhixQJJXOJVZe/ByV0EZESoYQu0gBNnQpdu0KTJuHn1KnZ7W/dunX07duXvn378oUvfIGOHTvWTG/fvj3lthUVFVx55ZVpjzFo0KDsgpS0dFNUpIGZOhXGjYMtW8L0ypVhGmD06Lrts23btixcuBCAG2+8kZYtW3LVVVfVLN+5cydNmyZOF+Xl5ZSXl6c9xssvv1y34Apo165dlJWVFTqMjKmELtLATJq0O5lX27IlzM+lMWPG8KMf/YiTTjqJa665hldeeYVBgwbRr18/Bg0axFtvvQXAiy++yJlnngmEL4OxY8cyZMgQDj/8cO64446a/bVs2bJm/SFDhnDuuefSo0cPRo8ejXvoTWT27Nn06NGDwYMHc+WVV9bsN9aKFSv4yle+Qv/+/enfv/8eXxS//OUv6d27N3369GHixNDT97Jlyzj55JPp06cP/fv35913390jZoArrriC+++/H4CuXbty0003MXjwYB577DHuvvtujj32WPr06cM555zDlujkr169mhEjRtCnTx/69OnDyy+/zHXXXcftt99es99JkybtcQ7yTSV0kQbm/fdrNz8bb7/9NnPmzKGsrIyNGzfy0ksv0bRpU+bMmcNPfvITnnjiib22efPNN3nhhRfYtGkTX/ziF5kwYcJebalfffVVlixZwqGHHsrxxx/P3//+d8rLy7n00kt56aWX6NatG6NGjUoY08EHH8xzzz1H8+bNeeeddxg1ahQVFRU8/fTTzJw5k3/961+0aNGC9evXAzB69GgmTpzIiBEj2Lp1K1VVVaxatSrhvqs1b96cv/3tb0Cojvrud78LwE9/+lPuuecevve973HllVdy4oknMmPGDHbt2sXmzZs59NBDOfvss/n+979PVVUV06dP55VXXqn1ea8rJXSRBuaww0I1S6L5uXbeeefVVDls2LCBiy++mHfeeQczY8eOHQm3OeOMM9h3333Zd999Ofjgg1m9ejWdOnXaY52BAwfWzOvbty8rVqygZcuWHH744TXtrkeNGsWUKVP22v+OHTu44oorWLhwIWVlZbz99tsAzJkzh0suuYQWLVoAcNBBB7Fp0yY++OADRowYAYREnYkLLrig5v3rr7/OT3/6Uz777DM2b97MqaeeCsDzzz/Pgw8+CEBZWRmtW7emdevWtG3blldffZXVq1fTr18/2rZtm9Exc0EJXaSBmTx5zzp0gBYtwvxc23///WveX3fddZx00knMmDGDFStWMGTIkITb7LvvvjXvy8rK2LlzZ0brVFe7pHPrrbdyyCGHsGjRIqqqqmqStLvv1dQv2T6bNm1KVVVVzXR8e+/Yzz1mzBhmzpxJnz59uP/++3nxxRdTxved73yH+++/n48//pixY8dm9JlyRXXoIg3M6NEwZQp06QJm4eeUKXW/IZqpDRs20LFjGAqhur45l3r06MHy5ctZsWIFAI888kjSODp06ECTJk146KGH2LUr9Nr9ta99jXvvvbemjnv9+vUccMABdOrUiZkzZwKwbds2tmzZQpcuXVi6dCnbtm1jw4YNzJ07N2lcmzZtokOHDuzYsYOpMc2Jhg4dyl133QWEm6cbN24EYMSIETzzzDPMmzevpjRfX5TQRRqg0aNhxQqoqgo/853MAX784x9z7bXXcvzxx9ck0Vzab7/9+M1vfsOwYcMYPHgwhxxyCK1bt95rvcsuu4wHHniAL3/5y7z99ts1pelhw4Zx1llnUV5eTt++fbnlllsAeOihh7jjjjs45phjGDRoEB9//DGdO3fm/PPP55hjjmH06NH069cvaVw/+9nP+NKXvsQpp5xCjx49aubffvvtvPDCC/Tu3ZsBAwawZMkSAJo1a8ZJJ53E+eefX+8tZCzTy5xcKy8v94qKioIcW6TYvPHGGxx99NGFDqPgNm/eTMuWLXF3Lr/8crp3784Pf/jDQodVK1VVVfTv35/HHnuM7t27Z7WvRH8XZjbf3RO2E1UJXUSKxt13303fvn3p1asXGzZs4NJLLy10SLWydOlSjjzySIYOHZp1Mq8L3RQVkaLxwx/+sMGVyGP17NmT5cuXF+z4KqGLiJQIJXQRkRKhhC4iUiKU0EVESkRGCd3MhpnZW2a2zMwmJlg+3MwWm9lCM6sws8G5D1VE8mXIkCE8++yze8y77bbbuOyyy1JuU930+PTTT+ezzz7ba50bb7yxpj14MjNnzmTp0qU109dffz1z5sypRfRSLW1CN7My4E7gNKAnMMrMesatNhfo4+59gbHA/+Y4ThHJo1GjRjF9+vQ95k2fPj1pB1nxZs+eTZs2bep07PiEftNNN3HyySfXaV+Fko8HreoikxL6QGCZuy939+3AdGB47Aruvtl3P6G0P1CYp5VESsAPfgBDhuT29YMfpD7mueeey1NPPcW2bduA0EXthx9+yODBg5kwYQLl5eX06tWLG264IeH2Xbt2Ze3atQBMnjyZL37xi5x88sk1XewCCbuhffnll5k1axZXX301ffv25d1332XMmDE8/vjjAMydO5d+/frRu3dvxo4dWxNf165dueGGG+jfvz+9e/fmzTff3CumxtjNbiYJvSMQ29dkZTRvD2Y2wszeBP5EKKXvxczGRVUyFWvWrKlLvCKSB23btmXgwIE888wzQCidX3DBBZgZkydPpqKigsWLF/OXv/yFxYsXJ93P/PnzmT59Oq+++ipPPvkk8+bNq1l29tlnM2/ePBYtWsTRRx/NPffcw6BBgzjrrLO4+eabWbhwIUcccUTN+lu3bmXMmDE88sgjvPbaa+zcubOm7xSAdu3asWDBAiZMmJCwWqe6m90FCxbwyCOP1IyqFNvN7qJFi/jxj38MhG52L7/8chYtWsTLL79Mhw4d0p636m52R44cmfDzATXd7C5atIgFCxbQq1cvvv3tb/PAAw8A1HSzOzoH/Tdk8mBRopFK9yqBu/sMYIaZnQD8DNjrmsndpwBTIDz6X7tQRRqH224rzHGrq12GDx/O9OnTuffeewF49NFHmTJlCjt37uSjjz5i6dKlHHPMMQn38de//pURI0bUdGF71lln1SxL1g1tMm+99RbdunXjqKOOAuDiiy/mzjvv5AfR5cbZZ58NwIABA3jyySf32r4xdrObSQm9EugcM90J+DDZyu7+EnCEmbXLMra95HocRRHZ7Rvf+AZz585lwYIFfP755/Tv35/33nuPW265hblz57J48WLOOOOMvbqajZdstPoxY8bw61//mtdee40bbrgh7X7S9TNV3QVvsi56Y7vZraioqBkbNZ/d7Nbm81V3s3vfffflrJvdTBL6PKC7mXUzs2bASGBW7ApmdqRFZ8jM+gPNgHU5iTBSPY7iypXgvnscRSV1kdxo2bIlQ4YMYezYsTU3Qzdu3Mj+++9P69atWb16NU8//XTKfZxwwgnMmDGDzz//nE2bNvHHP/6xZlmybmhbtWrFpk2b9tpXjx49WLFiBcuWLQNCr4knnnhixp+nMXazmzahu/tO4ArgWeAN4FF3X2Jm481sfLTaOcDrZraQ0CLmAs9xN471NY6iSGM2atQoFi1axMiRIwHo06cP/fr1o1evXowdO5bjjz8+5fb9+/fnggsuoG/fvpxzzjl85StfqVmWrBvakSNHcvPNN9OvXz/efffdmvnNmzfnvvvu47zzzqN37940adKE8ePHk6nG2M1ug+k+t0mTUDKPZxb6hBZpyNR9buOTSTe7Jdt9brLxEvMxjqKISD7lq5vdBtN9bn2Ooygikk/56ma3wZTQCzWOokh9KVT1pxSnuvw9NJgSOoTkrQQupah58+asW7eOtm3bJm32J42Hu7Nu3bqM28NXa1AJXaRUderUicrKSvQEtVRr3rw5nTp1qtU2SugiRWCfffahW7duhQ5DGrgGU4cuIiKpKaGLiJQIJXQRkRJRsCdFzWwNsDLJ4nbA2noMp7aKPT4o/hgVX3YUX3Yacnxd3L19ogUFS+ipmFlFskdbi0GxxwfFH6Piy47iy06pxqcqFxGREqGELiJSIoo1oU8pdABpFHt8UPwxKr7sKL7slGR8RVmHLiIitVesJXQREaklJXQRkRJRdAndzIaZ2VtmtszMJhY6nnhmtsLMXjOzhWaW+ZBL+YvnXjP7xMxej5l3kJk9Z2bvRD8PLLL4bjSzD6JzuNDMTi9gfJ3N7AUze8PMlpjZ96P5RXEOU8RXFOfQzJqb2StmtiiK7z+j+cVy/pLFVxTnLybOMjN71cyeiqbrdP6Kqg7dzMqAt4FTgErCANWj3H1pQQOLYWYrgHJ3L4qHEszsBGAz8KC7/0c075fAenf/efSleKC7X1NE8d0IbHb3WwoRUywz6wB0cPcFZtYKmA98AxhDEZzDFPGdTxGcw2hw+P3dfbOZ7QP8Dfg+cDbFcf6SxTeMIjh/1czsR0A5cIC7n1nX/+FiK6EPBJa5+3J33w5MB4YXOKai5u4vAevjZg8HHojeP0BIAAWRJL6i4e4fufuC6P0mwkDoHSmSc5givqLgweZocp/o5RTP+UsWX9Ews07AGcD/xsyu0/krtoTeEVgVM11JEf3xRhz4s5nNN7NxhQ4miUPc/SMICQE4uMDxJHKFmS2OqmQKViUUy8y6Av2Af1GE5zAuPiiScxhVFywEPgGec/eiOn9J4oMiOX/AbcCPgdjh7ut0/ootoScaqqWovk2B4929P3AacHlUpSC1cxdwBNAX+Aj4n4JGA5hZS+AJ4AfuvrHQ8cRLEF/RnEN33+XufYFOwEAz+49CxZJIkviK4vyZ2ZnAJ+4+Pxf7K7aEXgl0jpnuBHxYoFgScvcPo5+fADMI1UTFZnVU91pdB/tJgePZg7uvjv7JqoC7KfA5jOpWnwCmuvuT0eyiOYeJ4iu2cxjF9BnwIqF+umjOX7XY+Iro/B0PnBXdm5sOfNXMHqaO56/YEvo8oLuZdTOzZsBIYFaBY6phZvtHN6Yws/2BrwGvp96qIGYBF0fvLwb+UMBY9lL9hxoZQQHPYXTT7B7gDXf/VcyiojiHyeIrlnNoZu3NrE30fj/gZOBNiuf8JYyvWM6fu1/r7p3cvSsh3z3v7hdR1/Pn7kX1Ak4ntHR5F5hU6HjiYjscWBS9lhRDfMA0wiXjDsIVzreBtsBc4J3o50FFFt9DwGvA4ugPt0MB4xtMqNZbDCyMXqcXyzlMEV9RnEPgGODVKI7Xgeuj+cVy/pLFVxTnLy7WIcBT2Zy/omq2KCIidVdsVS4iIlJHSugiIiVCCV1EpEQooYuIlAgldBGREqGELiJSIpTQRURKxP8HNINa/K8m3IYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying curves of loss and accuracy during training\n",
    "\n",
    "for i in range(5):\n",
    "    acc = list_of_histories[i].history[\"accuracy\"]\n",
    "    val_acc = list_of_histories[i].history[\"val_accuracy\"]\n",
    "    loss = list_of_histories[i].history[\"loss\"]\n",
    "    val_loss = list_of_histories[i].history[\"val_loss\"]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a13455e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[200704,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9412/2097470252.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_Fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mall_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_best_model'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    199\u001b[0m         if (h5py is not None and\n\u001b[0;32m    200\u001b[0m             (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 201\u001b[1;33m           return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0m\u001b[0;32m    202\u001b[0m                                                   compile)\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    178\u001b[0m       \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     model = model_config_lib.model_from_config(model_config,\n\u001b[0m\u001b[0;32m    181\u001b[0m                                                custom_objects=custom_objects)\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     57\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m     58\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    157\u001b[0m   \"\"\"\n\u001b[0;32m    158\u001b[0m   \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m   return generic_utils.deserialize_keras_object(\n\u001b[0m\u001b[0;32m    160\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'custom_objects'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         deserialized_obj = cls.from_config(\n\u001b[0m\u001b[0;32m    669\u001b[0m             \u001b[0mcls_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             custom_objects=dict(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    666\u001b[0m     \"\"\"\n\u001b[0;32m    667\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSharedObjectLoadingScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m       input_tensors, output_tensors, created_layers = reconstruct_from_config(\n\u001b[0m\u001b[0;32m    669\u001b[0m           config, custom_objects)\n\u001b[0;32m    670\u001b[0m       model = cls(inputs=input_tensors, outputs=output_tensors,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mreconstruct_from_config\u001b[1;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[0;32m   1287\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1289\u001b[1;33m           \u001b[0mprocess_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m   \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mprocess_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1235\u001b[0m         input_tensors = (\n\u001b[0;32m   1236\u001b[0m             base_layer_utils.unnest_if_single_tensor(input_tensors))\n\u001b[1;32m-> 1237\u001b[1;33m       \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m       \u001b[1;31m# Update node index map.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    876\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2623\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2624\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2625\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2626\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2627\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                        'should be defined. Found `None`.')\n\u001b[0;32m   1190\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m     self.kernel = self.add_weight(\n\u001b[0m\u001b[0;32m   1192\u001b[0m         \u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlast_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mcaching_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m     variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[0;32m    640\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    808\u001b[0m         \u001b[1;31m# \"best effort\" to set the initializer with the highest restore UID.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m     new_variable = getter(\n\u001b[0m\u001b[0;32m    811\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# can remove the V1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m   \u001b[0mvariable_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   return tf_variables.VariableV1(\n\u001b[0m\u001b[0;32m    128\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     return previous_getter(\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m                         shape=None):\n\u001b[0;32m    198\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2610\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2611\u001b[0m     \u001b[0mdistribute_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"distribute_strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2612\u001b[1;33m     return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[0;32m   2613\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2614\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1582\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1584\u001b[1;33m       self._init_from_args(\n\u001b[0m\u001b[0;32m   1585\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1586\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1720\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1721\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1722\u001b[1;33m               \u001b[0minitial_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1723\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1724\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m       \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m     return op(\n\u001b[0m\u001b[0;32m    979\u001b[0m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    307\u001b[0m           shape, minval, maxval, seed=seed1, seed2=seed2, name=name)\n\u001b[0;32m    308\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m       result = gen_random_ops.random_uniform(\n\u001b[0m\u001b[0;32m    310\u001b[0m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0;32m    311\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[0;32m    718\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6896\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6897\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6898\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GPU\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[200704,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "all_model=[]\n",
    "\n",
    "for i in range(N_Fold):\n",
    "    all_model.append(load_model('my_best_model'+str(i+1)+'.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ccaaf17",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9412/2001795473.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel_predict_moyenne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX2_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_Fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "\n",
    "    model_predict_moyenne = all_model[0].predict([X1_test,X2_test])\n",
    "\n",
    "    for i in range(1,N_Fold):\n",
    "        model_predict_moyenne = model_predict_moyenne + all_model[i].predict([X1_test,X2_test])\n",
    "\n",
    "    model_predict_moyenne = model_predict_moyenne/N_Fold\n",
    "\n",
    "    # Calcul prcision de mthode k_fold\n",
    "    print(np.mean(np.argmax(model_predict_moyenne, axis = 1)==y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
